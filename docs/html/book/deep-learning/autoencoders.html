
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Autoencoders &#8212; Data Science Hand.. 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/style.css" />
    <link rel="stylesheet" href="../../_static/css/style.css" type="text/css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html">
          Handbook</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Section <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Autoencoders</a><ul>
<li><a class="reference internal" href="#autoencoders-overview">Autoencoders Overview</a><ul>
<li><a class="reference internal" href="#lstm-autoencoder">LSTM Autoencoder</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="autoencoders">
<h1>Autoencoders<a class="headerlink" href="#autoencoders" title="Permalink to this headline"></a></h1>
<hr class="docutils" />
<div class="section" id="autoencoders-overview">
<h2>Autoencoders Overview<a class="headerlink" href="#autoencoders-overview" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">autoencoder</span></code> is a machine learning solution made up of two blocks,
encoder and decoder, whose  purpose is to obtain internal representations
usually with smaller dimensionality than the input. This process is known as
encoding.</p></li>
<li><p>For this representation to be obtained, the decoding phase is also necessary
so that the system can  encode efficiently the input data.</p></li>
<li><p>The purpose of this block of the autoencoder is to reconstruct the input
signal from the intermediate representation obtained by the encoder.</p></li>
<li><p>The difference between the reconstructed signal by the autoencoder and the
original input signal is  known as the reconstruction error.</p></li>
<li><p>In essence, the autoencoder tries to learn an identity function which makes
the output  be similar  to the input x.</p></li>
<li><p>By placing constraints on the network, such as a limitation in the number of
hidden units, interesting structure about the data can be discovered.</p></li>
<li><p><strong>Example</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Convolutional</span> <span class="pre">Autoencoders</span></code> are designed to encode the input into a set of
simpler signals and reconstruct the input from them.</p></li>
<li><p>The encoder layers are in this case convolutional layers and the decoder
layers are called <code class="docutils literal notranslate"><span class="pre">deconvolution</span></code> or <code class="docutils literal notranslate"><span class="pre">upsampling</span></code> layers.</p></li>
</ul>
</li>
</ul>
<div class="section" id="lstm-autoencoder">
<h3>LSTM Autoencoder<a class="headerlink" href="#lstm-autoencoder" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Recurrent neural networks, such as the Long Short-Term Memory, or LSTM,
network are specifically designed to support sequences of input data.</p></li>
<li><p>They are capable of learning the complex dynamics within the temporal
ordering of input sequences as  well as use an internal memory to remember or
use information across long input sequences.</p></li>
<li><p>The LSTM network can be organized into an architecture called the
Encoder-Decoder LSTM that allows  the model to be used to both support
variable length input sequences and to predict or output variable length
output sequences.</p></li>
<li><p>This architecture is the basis for many advances in complex sequence
prediction problems such as  speech recognition and text translation.</p></li>
<li><p>In this architecture, an encoder LSTM model reads the input sequence
step-by-step. After reading in  the entire input sequence, the hidden state
or output of this model represents an internal learned representation of the
entire input sequence as a fixed-length vector. This vector is then provided
as an input to the decoder model that interprets it as each step in the
output sequence is generated.</p></li>
<li><p>An <code class="docutils literal notranslate"><span class="pre">LSTM</span> <span class="pre">Autoencoder</span> </code>is an implementation of an autoencoder for sequence
data using an Encoder-Decoder LSTM architecture.</p></li>
<li><p>For a given dataset of sequences, an encoder-decoder LSTM is configured to
read the input sequence,  encode it, decode it, and recreate it.</p></li>
<li><p>The performance of the model is evaluated based on the model’s ability to
recreate the input  sequence.</p></li>
<li><p>Once the model achieves a desired level of performance recreating the
sequence, the decoder part of  the model may be removed, leaving just the
encoder model.</p></li>
<li><p>This model can then be used to encode input sequences to a fixed-length vector.</p></li>
</ul>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../../_sources/book/deep-learning/autoencoders.md.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2021, Trace Smith, Damon Resnick.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>